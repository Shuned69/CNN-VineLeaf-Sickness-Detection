{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VineLeafClassificationModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaTVOjcExylc"
      },
      "source": [
        " **Vine Leaf Sickness Identification Model**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc1Fq8xr0HcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc31d420-29c1-4e90-a243-67cae472c4f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEY3ctUz5ZPW"
      },
      "source": [
        "import datetime\n",
        "import os\n",
        "import os.path\n",
        "import random\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndwqJwEO57X0"
      },
      "source": [
        "We import tensor flow and different package which will be use later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n36egjms55hr"
      },
      "source": [
        "batch_size = 32\n",
        "TEST_PATH = \"\"\n",
        "VAL_PATH = \"\"\n",
        "TRAIN_PATH = \"\"\n",
        "IMAGE_SIZE = 200\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbD_kvlytJW2"
      },
      "source": [
        "We set up some variable for the next steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GANoIpM89xyT"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = (1./255),\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   rotation_range=90, \n",
        "                                   brightness_range=[0.2,1.0]\n",
        "                                   )\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdZIg-tjtN-0"
      },
      "source": [
        "We use ImageDataGenertator to create a data generator in whoch we will feed our dataset. Using this method allow us to generate a large quantities of datas thanks to data augmentation. We hence modifie the Images in various and random ways: first we rescale the value of our pixels in our images for a faster computing. We then applie a random rotation, shear, zoom and brightness to our images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpL8bcdh-G07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b225f06-ea18-496d-82c3-430c21af5ae0"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(r\"/content/gdrive/MyDrive/VineLeafDataSet/Dataset/Training\",\n",
        "                                                 target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                                 batch_size = BATCH_SIZE,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2101 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsqvAvVS-JpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3841a7-f35b-4685-ddf1-38ad125d752b"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory(r\"/content/gdrive/MyDrive/VineLeafDataSet/Dataset/Test\",\n",
        "                                            target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 660 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to1-vy1uDTd8",
        "outputId": "675a1780-bad2-478c-b4c8-2a6cbbeb453f"
      },
      "source": [
        "validation_set = test_datagen.flow_from_directory(r\"/content/gdrive/MyDrive/VineLeafDataSet/Dataset/Validation\",\n",
        "                                                 target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                                 batch_size = BATCH_SIZE,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 689 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xGPIqDWubuW"
      },
      "source": [
        "We then import our datas from our directories and resize all the images to the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70u9emtGD_Ga"
      },
      "source": [
        "def build_model():\n",
        "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    #x = layers.experimental.preprocessing.Rescaling(1. / 255)(inputs)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    x = layers.SeparableConv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.SeparableConv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.SeparableConv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.SeparableConv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    x = layers.SeparableConv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.SeparableConv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.SeparableConv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.SeparableConv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.7)(x)\n",
        "\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBM3JOF_u4Ad"
      },
      "source": [
        "We create our model using five time: Convolution Filter -> Convolution Filter -> Batchnormalization -> Max Pooling -> Dropout (optional)\n",
        "Batchnormalization and dropout are there to avoid the overfitting of our model to the dataset.\n",
        "\n",
        "We then Flatten the output of the Convolution networks and add three Dense layers with batchnormalization layers and dropout layers.\n",
        "\n",
        "Our last output layer is a Dense layer of one unit since we set the labels mode to binary with and sigmoid activation which fit the binary output. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgY_BP2Eu5L"
      },
      "source": [
        "METRICS = [\n",
        "    tf.keras.metrics.BinaryAccuracy(),\n",
        "    tf.keras.metrics.Precision(name=\"precision\"),\n",
        "    tf.keras.metrics.Recall(name=\"recall\"),\n",
        "    tf.keras.metrics.AUC(name=\"auc\"),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdP1zb8Hu7ha"
      },
      "source": [
        "We setup the metrics we will use to evaluate our model. Binary Accuracy and the AUC metrics are our most important parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CZCK-GbIg4w"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk15_SVdu_ue"
      },
      "source": [
        "We create the different callbacks for the training:\n",
        "- a checkpoint to save our model which performed the best based on its result on the validation set\n",
        "\n",
        "- an early stoping to stop our model traing when he begin to overfitt.\n",
        "\n",
        "- A callback for tensorboard to save the training and validation logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6PAT8rlFCF2"
      },
      "source": [
        "initial_learning_rate = 0.015\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.95, staircase=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3tMSBRHvGOU"
      },
      "source": [
        "We set a learning rate for our optimizer to have better result and avoid the plateau.\n",
        "\n",
        "We then compile our model using Adam as our optimizer feeding it the learning rate schedule. We base the loss of our model with binary_crossentropy sinc our labels are in binary modes and we add the metrics defined erlier to our compilation. \n",
        "We set a learning rate for our optimizer to have better result and avoid the plateau.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3iv57LtE4Lg"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=METRICS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQwISfBlvPOT"
      },
      "source": [
        "We then compile our model using Adam as our optimizer feeding it the learning rate schedule. We base the loss of our model with binary_crossentropy sinc our labels are in binary modes and we add the metrics defined erlier to our compilation. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndEuA0nkE8JI",
        "outputId": "0d6caf69-9567-4cb8-e6ab-a10014ecf6aa"
      },
      "source": [
        "model.fit(training_set, validation_data=validation_set, epochs=100, verbose=1, callbacks=[tensorboard_callback, checkpoint, early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "66/66 [==============================] - 641s 10s/step - loss: 0.6942 - binary_accuracy: 0.6406 - precision: 0.6241 - recall: 0.3980 - auc: 0.6268 - val_loss: 87.1119 - val_binary_accuracy: 0.4020 - val_precision: 0.4020 - val_recall: 1.0000 - val_auc: 0.5000\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 254s 4s/step - loss: 0.5776 - binary_accuracy: 0.7211 - precision: 0.7613 - recall: 0.5050 - auc: 0.7366 - val_loss: 3.4557 - val_binary_accuracy: 0.3948 - val_precision: 0.3841 - val_recall: 0.8375 - val_auc: 0.5391\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 250s 4s/step - loss: 0.5390 - binary_accuracy: 0.7611 - precision: 0.7988 - recall: 0.5886 - auc: 0.7819 - val_loss: 8.5752 - val_binary_accuracy: 0.3832 - val_precision: 0.3858 - val_recall: 0.9025 - val_auc: 0.4455\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 265s 4s/step - loss: 0.5207 - binary_accuracy: 0.7744 - precision: 0.8209 - recall: 0.6031 - auc: 0.7915 - val_loss: 5.6749 - val_binary_accuracy: 0.3933 - val_precision: 0.3900 - val_recall: 0.9025 - val_auc: 0.4760\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 252s 4s/step - loss: 0.5111 - binary_accuracy: 0.7858 - precision: 0.8057 - recall: 0.6566 - auc: 0.8107 - val_loss: 1.0937 - val_binary_accuracy: 0.6415 - val_precision: 0.5487 - val_recall: 0.6101 - val_auc: 0.7069\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 263s 4s/step - loss: 0.4783 - binary_accuracy: 0.8049 - precision: 0.8359 - recall: 0.6756 - auc: 0.8331 - val_loss: 1.0035 - val_binary_accuracy: 0.6967 - val_precision: 0.6453 - val_recall: 0.5451 - val_auc: 0.7023\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 251s 4s/step - loss: 0.4704 - binary_accuracy: 0.8010 - precision: 0.8241 - recall: 0.6789 - auc: 0.8479 - val_loss: 1.2967 - val_binary_accuracy: 0.5283 - val_precision: 0.4442 - val_recall: 0.6895 - val_auc: 0.6634\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 254s 4s/step - loss: 0.4902 - binary_accuracy: 0.7944 - precision: 0.8507 - recall: 0.6288 - auc: 0.8278 - val_loss: 0.9986 - val_binary_accuracy: 0.5660 - val_precision: 0.4701 - val_recall: 0.6245 - val_auc: 0.6671\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 251s 4s/step - loss: 0.4517 - binary_accuracy: 0.8267 - precision: 0.8780 - recall: 0.6901 - auc: 0.8449 - val_loss: 0.7177 - val_binary_accuracy: 0.7358 - val_precision: 0.7879 - val_recall: 0.4693 - val_auc: 0.7363\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 263s 4s/step - loss: 0.4172 - binary_accuracy: 0.8372 - precision: 0.8970 - recall: 0.6990 - auc: 0.8719 - val_loss: 0.7316 - val_binary_accuracy: 0.7344 - val_precision: 0.7866 - val_recall: 0.4657 - val_auc: 0.7226\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 255s 4s/step - loss: 0.4632 - binary_accuracy: 0.8077 - precision: 0.8516 - recall: 0.6656 - auc: 0.8476 - val_loss: 0.6196 - val_binary_accuracy: 0.6938 - val_precision: 0.6650 - val_recall: 0.4801 - val_auc: 0.7427\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 263s 4s/step - loss: 0.4557 - binary_accuracy: 0.8091 - precision: 0.8425 - recall: 0.6800 - auc: 0.8521 - val_loss: 0.8292 - val_binary_accuracy: 0.7068 - val_precision: 0.6448 - val_recall: 0.6029 - val_auc: 0.7466\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 252s 4s/step - loss: 0.4371 - binary_accuracy: 0.8220 - precision: 0.8401 - recall: 0.7202 - auc: 0.8650 - val_loss: 0.7745 - val_binary_accuracy: 0.6851 - val_precision: 0.6230 - val_recall: 0.5487 - val_auc: 0.7295\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 263s 4s/step - loss: 0.4282 - binary_accuracy: 0.8215 - precision: 0.8595 - recall: 0.6957 - auc: 0.8667 - val_loss: 0.6093 - val_binary_accuracy: 0.7213 - val_precision: 0.7073 - val_recall: 0.5235 - val_auc: 0.7618\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 250s 4s/step - loss: 0.4221 - binary_accuracy: 0.8277 - precision: 0.8639 - recall: 0.7079 - auc: 0.8734 - val_loss: 0.8371 - val_binary_accuracy: 0.6038 - val_precision: 0.6250 - val_recall: 0.0361 - val_auc: 0.5284\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 263s 4s/step - loss: 0.4161 - binary_accuracy: 0.8334 - precision: 0.8847 - recall: 0.7012 - auc: 0.8732 - val_loss: 0.8139 - val_binary_accuracy: 0.6705 - val_precision: 0.5887 - val_recall: 0.5993 - val_auc: 0.7312\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 253s 4s/step - loss: 0.4033 - binary_accuracy: 0.8382 - precision: 0.8641 - recall: 0.7369 - auc: 0.8891 - val_loss: 0.8352 - val_binary_accuracy: 0.6589 - val_precision: 0.5755 - val_recall: 0.5776 - val_auc: 0.7226\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 262s 4s/step - loss: 0.4051 - binary_accuracy: 0.8334 - precision: 0.8793 - recall: 0.7068 - auc: 0.8880 - val_loss: 1.1007 - val_binary_accuracy: 0.5980 - val_precision: 0.5000 - val_recall: 0.5812 - val_auc: 0.6855\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 250s 4s/step - loss: 0.4115 - binary_accuracy: 0.8348 - precision: 0.8809 - recall: 0.7090 - auc: 0.8796 - val_loss: 0.6153 - val_binary_accuracy: 0.7054 - val_precision: 0.6697 - val_recall: 0.5271 - val_auc: 0.7623\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 266s 4s/step - loss: 0.4050 - binary_accuracy: 0.8348 - precision: 0.8757 - recall: 0.7146 - auc: 0.8844 - val_loss: 1.0209 - val_binary_accuracy: 0.5936 - val_precision: 0.3333 - val_recall: 0.0108 - val_auc: 0.6121\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 263s 4s/step - loss: 0.4021 - binary_accuracy: 0.8353 - precision: 0.8821 - recall: 0.7090 - auc: 0.8862 - val_loss: 0.8512 - val_binary_accuracy: 0.6546 - val_precision: 0.5777 - val_recall: 0.5235 - val_auc: 0.6677\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 251s 4s/step - loss: 0.4292 - binary_accuracy: 0.8239 - precision: 0.8634 - recall: 0.6979 - auc: 0.8589 - val_loss: 0.9067 - val_binary_accuracy: 0.6299 - val_precision: 0.5331 - val_recall: 0.6390 - val_auc: 0.7202\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 250s 4s/step - loss: 0.4445 - binary_accuracy: 0.8229 - precision: 0.8661 - recall: 0.6923 - auc: 0.8575 - val_loss: 0.9897 - val_binary_accuracy: 0.6633 - val_precision: 0.8169 - val_recall: 0.2094 - val_auc: 0.7111\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 262s 4s/step - loss: 0.4302 - binary_accuracy: 0.8310 - precision: 0.8871 - recall: 0.6923 - auc: 0.8658 - val_loss: 1.0871 - val_binary_accuracy: 0.5994 - val_precision: 0.5333 - val_recall: 0.0289 - val_auc: 0.5648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe3508bae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PlR9-V-vbG6"
      },
      "source": [
        "We then train our model. Using our train/validation split, for 100 epoch since we have an early stopping anyway."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyiZgAEgE99f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028a8b58-beef-4197-b2a0-1dd04e98a409"
      },
      "source": [
        "model.load_weights(\"/content/best_model.h5\")\n",
        "model.evaluate(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 133s 7s/step - loss: 0.6437 - binary_accuracy: 0.6773 - precision: 0.7748 - recall: 0.5134 - auc: 0.7824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.643674373626709,\n",
              " 0.6772727370262146,\n",
              " 0.7747747898101807,\n",
              " 0.5134328603744507,\n",
              " 0.7824156284332275]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlAM4SUTveNJ"
      },
      "source": [
        "We load the model which performed the best and evalute it using out test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W22_0nkgrl9H",
        "outputId": "4a9b3376-275e-4a9d-caea-9967542238d2"
      },
      "source": [
        "def get_random_leaf_picture():\n",
        "    PATH = [\"/content/gdrive/MyDrive/VineLeafDataSet/Dataset/Test/Malade\", \"/content/gdrive/MyDrive/VineLeafDataSet/Dataset/Test/Saine/\"]\n",
        "    rand = random.randint(0, 1)\n",
        "    rand_file = random.choice(os.listdir(PATH[rand]))\n",
        "    if rand == 0:\n",
        "        rand_file = \"/content/gdrive/MyDrive/VineLeafDataSet/Dataset/Test/Malade/\" + rand_file\n",
        "        print(\"this Leaf is sick\")\n",
        "    else:\n",
        "        rand_file = \"/content/gdrive/MyDrive/VineLeafDataSet/Dataset/Test/Saine/\" + rand_file\n",
        "        print(\"this Leaf is normal\")\n",
        "    return rand_file\n",
        "\n",
        "model.load_weights(\"best_model.h5\")\n",
        "\n",
        "for i in range(10):\n",
        "    file_name = get_random_leaf_picture()\n",
        "    img = keras.preprocessing.image.load_img(\n",
        "        file_name, target_size=(IMAGE_SIZE, IMAGE_SIZE)\n",
        "    )\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    score = predictions[0]\n",
        "    print(\n",
        "        \"This image is %.2f percent Normal and %.2f percent Sick.\"\n",
        "        % (100 * (1 - score), 100 * score)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this Leaf is sick\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is normal\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is normal\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is normal\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is normal\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is normal\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is sick\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is sick\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is normal\n",
            "This image is 0.00 percent Normal and 100.00 percent Sick.\n",
            "this Leaf is normal\n",
            "This image is 69.17 percent Normal and 30.83 percent Sick.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eetn0NdDvjb-"
      },
      "source": [
        "We created a simple fonction which pick 10 random images from the test dataset and test our model with those images, diplaying our leaf images scores of Sick or Normal."
      ]
    }
  ]
}